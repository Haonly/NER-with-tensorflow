{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1.Build**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.config import Config\n",
    "from model.data_utils import CoNLLDataset,get_vocabs,UNK,NUM,get_glove_vocab,write_vocab,load_vocab,get_char_vocab,export_trimmed_glove_vectors,get_processing_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=Config(load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_word=get_processing_word(lowercase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=CoNLLDataset(config.filename_train,processing_word)\n",
    "dev=CoNLLDataset(config.filename_dev,processing_word)\n",
    "test=CoNLLDataset(config.filename_test,processing_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. 단어와 tags에 대해 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocab...\n",
      "-done. 26054 tokens\n"
     ]
    }
   ],
   "source": [
    "vocab_words,vocab_tags=get_vocabs([train,dev,test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. GloVe의 단어만 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocab...\n",
      "-done. 400000 tokens\n"
     ]
    }
   ],
   "source": [
    "vocab_glove=get_glove_vocab(config.filename_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Dataset의 단어와 GloVe 단어의 교집합 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=vocab_words&vocab_glove\n",
    "vocab.add(UNK)\n",
    "vocab.add(NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. 단어와 tag를 .txt 파일로 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing vocab...\n",
      "- done. 22217 tokens\n",
      "Writing vocab...\n",
      "- done. 9 tokens\n"
     ]
    }
   ],
   "source": [
    "write_vocab(vocab,config.filename_words)\n",
    "write_vocab(vocab_tags,config.filename_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. 단어를 load하여 glove embedding을 npz 파일로 압축 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=load_vocab(config.filename_words)\n",
    "export_trimmed_glove_vectors(vocab,config.filename_glove,config.filename_trimmed,config.dim_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Character를 중복 제거 후 .txt 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=CoNLLDataset(config.filename_train)\n",
    "vocab_chars=get_char_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing vocab...\n",
      "- done. 84 tokens\n"
     ]
    }
   ],
   "source": [
    "write_vocab(vocab_chars,config.filename_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.data_utils import CoNLLDataset\n",
    "from model.ner_model import NERModel\n",
    "from model.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NERModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0823 09:05:18.677439 140272046606144 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/ner_model.py:19: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0823 09:05:18.700027 140272046606144 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/ner_model.py:72: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0823 09:05:18.890761 140272046606144 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/ner_model.py:116: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0823 09:05:18.892025 140272046606144 deprecation.py:506] From /home/haonly/anaconda3/envs/hayeon/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0823 09:05:18.911437 140272046606144 deprecation.py:323] From /home/haonly/ner with tensor_v5/model/ner_model.py:130: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character - CNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 09:05:19.123501 140272046606144 deprecation.py:573] From /home/haonly/anaconda3/envs/hayeon/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "W0823 09:05:19.126209 140272046606144 deprecation.py:323] From /home/haonly/ner with tensor_v5/model/ner_model.py:142: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0823 09:05:19.332236 140272046606144 deprecation.py:506] From /home/haonly/ner with tensor_v5/model/ner_model.py:146: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0823 09:05:19.660881 140272046606144 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0823 09:05:19.662041 140272046606144 deprecation.py:323] From /home/haonly/ner with tensor_v5/model/ner_model.py:154: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0823 09:05:19.663330 140272046606144 deprecation.py:323] From /home/haonly/ner with tensor_v5/model/ner_model.py:160: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "W0823 09:05:19.664361 140272046606144 deprecation.py:323] From /home/haonly/anaconda3/envs/hayeon/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0823 09:05:19.731748 140272046606144 deprecation.py:506] From /home/haonly/anaconda3/envs/hayeon/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0823 09:05:20.202215 140272046606144 deprecation.py:323] From /home/haonly/anaconda3/envs/hayeon/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0823 09:05:20.379494 140272046606144 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/base_model.py:23: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "I0823 09:05:21.182184 140272046606144 base_model.py:27] Initializing tf session\n",
      "W0823 09:05:21.183353 140272046606144 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/base_model.py:28: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0823 09:05:21.219236 140272046606144 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/base_model.py:29: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0823 09:05:21.935987 140272046606144 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/base_model.py:30: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev=CoNLLDataset(config.filename_dev,config.processing_word,config.processing_tag,config.max_iter)\n",
    "train=CoNLLDataset(config.filename_train,config.processing_word,config.processing_tag,config.max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:05:22.008518 140272046606144 base_model.py:50] Epoch 1 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 61s - train loss: 0.2691    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:06:29.647119 140272046606144 ner_model.py:240] acc 97.29 - f1 84.46\n",
      "I0823 09:06:30.060101 140272046606144 base_model.py:60] - new best score!\n",
      "I0823 09:06:30.061471 140272046606144 base_model.py:50] Epoch 2 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.1084    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:07:36.251449 140272046606144 ner_model.py:240] acc 98.04 - f1 88.48\n",
      "I0823 09:07:36.598556 140272046606144 base_model.py:60] - new best score!\n",
      "I0823 09:07:36.599701 140272046606144 base_model.py:50] Epoch 3 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 58s - train loss: 0.0801    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:08:40.417403 140272046606144 ner_model.py:240] acc 98.26 - f1 89.88\n",
      "I0823 09:08:40.760363 140272046606144 base_model.py:60] - new best score!\n",
      "I0823 09:08:40.761992 140272046606144 base_model.py:50] Epoch 4 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.0634    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:09:47.005294 140272046606144 ner_model.py:240] acc 98.49 - f1 91.39\n",
      "I0823 09:09:47.351901 140272046606144 base_model.py:60] - new best score!\n",
      "I0823 09:09:47.353284 140272046606144 base_model.py:50] Epoch 5 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.0523    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:10:53.438869 140272046606144 ner_model.py:240] acc 98.56 - f1 91.98\n",
      "I0823 09:10:53.793607 140272046606144 base_model.py:60] - new best score!\n",
      "I0823 09:10:53.794961 140272046606144 base_model.py:50] Epoch 6 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.0445    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:11:59.927935 140272046606144 ner_model.py:240] acc 98.62 - f1 92.03\n",
      "I0823 09:12:00.279064 140272046606144 base_model.py:60] - new best score!\n",
      "I0823 09:12:00.280415 140272046606144 base_model.py:50] Epoch 7 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.0386    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:13:06.401849 140272046606144 ner_model.py:240] acc 98.59 - f1 91.80\n",
      "I0823 09:13:06.403588 140272046606144 base_model.py:50] Epoch 8 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.0323    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:14:12.605163 140272046606144 ner_model.py:240] acc 98.68 - f1 92.49\n",
      "I0823 09:14:12.936190 140272046606144 base_model.py:60] - new best score!\n",
      "I0823 09:14:12.937441 140272046606144 base_model.py:50] Epoch 9 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.0282    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:15:19.193493 140272046606144 ner_model.py:240] acc 98.72 - f1 92.32\n",
      "I0823 09:15:19.195132 140272046606144 base_model.py:50] Epoch 10 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.0248    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:16:25.392929 140272046606144 ner_model.py:240] acc 98.74 - f1 92.66\n",
      "I0823 09:16:25.733146 140272046606144 base_model.py:60] - new best score!\n",
      "I0823 09:16:25.734269 140272046606144 base_model.py:50] Epoch 11 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.0224    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:17:31.825759 140272046606144 ner_model.py:240] acc 98.75 - f1 92.89\n",
      "I0823 09:17:32.161213 140272046606144 base_model.py:60] - new best score!\n",
      "I0823 09:17:32.162473 140272046606144 base_model.py:50] Epoch 12 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.0200    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:18:38.200482 140272046606144 ner_model.py:240] acc 98.77 - f1 92.90\n",
      "I0823 09:18:38.486832 140272046606144 base_model.py:60] - new best score!\n",
      "I0823 09:18:38.488040 140272046606144 base_model.py:50] Epoch 13 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.0185    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:19:44.649850 140272046606144 ner_model.py:240] acc 98.81 - f1 93.24\n",
      "I0823 09:19:44.977142 140272046606144 base_model.py:60] - new best score!\n",
      "I0823 09:19:44.978343 140272046606144 base_model.py:50] Epoch 14 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.0171    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:20:51.118918 140272046606144 ner_model.py:240] acc 98.81 - f1 93.26\n",
      "I0823 09:20:51.459240 140272046606144 base_model.py:60] - new best score!\n",
      "I0823 09:20:51.460406 140272046606144 base_model.py:50] Epoch 15 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 60s - train loss: 0.0154    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:21:57.560837 140272046606144 ner_model.py:240] acc 98.82 - f1 93.26\n"
     ]
    }
   ],
   "source": [
    "model.train(train,dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3.Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.data_utils import CoNLLDataset\n",
    "from model.ner_model import NERModel\n",
    "from model.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_data(data):\n",
    "    \"\"\"Given dict with lists, creates aligned strings\n",
    "\n",
    "    Adapted from Assignment 3 of CS224N\n",
    "\n",
    "    Args:\n",
    "        data: (dict) data[\"x\"] = [\"I\", \"love\", \"you\"]\n",
    "              (dict) data[\"y\"] = [\"O\", \"O\", \"O\"]\n",
    "\n",
    "    Returns:\n",
    "        data_aligned: (dict) data_align[\"x\"] = \"I love you\"\n",
    "                           data_align[\"y\"] = \"O O    O  \"\n",
    "\n",
    "    \"\"\"\n",
    "    spacings = [max([len(seq[i]) for seq in data.values()])\n",
    "                for i in range(len(data[list(data.keys())[0]]))]\n",
    "    data_aligned = dict()\n",
    "\n",
    "    # for each entry, create aligned string\n",
    "    for key, seq in data.items():\n",
    "        str_aligned = \"\"\n",
    "        for token, spacing in zip(seq, spacings):\n",
    "            str_aligned += token + \" \" * (spacing - len(token) + 1)\n",
    "\n",
    "        data_aligned[key] = str_aligned\n",
    "\n",
    "    return data_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_shell(model):\n",
    "    \"\"\"Creates interactive shell to play with model\n",
    "\n",
    "    Args:\n",
    "        model: instance of NERModel\n",
    "\n",
    "    \"\"\"\n",
    "    model.logger.info(\"\"\"\n",
    "This is an interactive mode.\n",
    "To exit, enter 'exit'.\n",
    "You can enter a sentence like\n",
    "input> I love Paris\"\"\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # for python 2\n",
    "            sentence = raw_input(\"input> \")\n",
    "        except NameError:\n",
    "            # for python 3\n",
    "            sentence = input(\"input> \")\n",
    "\n",
    "        words_raw = sentence.strip().split(\" \")\n",
    "\n",
    "        if words_raw == [\"exit\"]:\n",
    "            break\n",
    "\n",
    "        preds = model.predict(words_raw)\n",
    "        to_print = align_data({\"input\": words_raw, \"output\": preds})\n",
    "\n",
    "        for key, seq in to_print.items():\n",
    "            model.logger.info(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NERModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0823 09:22:09.024690 140449374000960 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/ner_model.py:19: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0823 09:22:09.046135 140449374000960 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/ner_model.py:72: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0823 09:22:09.210677 140449374000960 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/ner_model.py:116: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0823 09:22:09.211990 140449374000960 deprecation.py:506] From /home/haonly/anaconda3/envs/hayeon/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0823 09:22:09.233058 140449374000960 deprecation.py:323] From /home/haonly/ner with tensor_v5/model/ner_model.py:130: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character - CNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 09:22:09.450004 140449374000960 deprecation.py:573] From /home/haonly/anaconda3/envs/hayeon/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "W0823 09:22:09.451181 140449374000960 deprecation.py:323] From /home/haonly/ner with tensor_v5/model/ner_model.py:142: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0823 09:22:09.657487 140449374000960 deprecation.py:506] From /home/haonly/ner with tensor_v5/model/ner_model.py:146: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0823 09:22:09.992774 140449374000960 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0823 09:22:09.993892 140449374000960 deprecation.py:323] From /home/haonly/ner with tensor_v5/model/ner_model.py:154: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0823 09:22:09.995098 140449374000960 deprecation.py:323] From /home/haonly/ner with tensor_v5/model/ner_model.py:160: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "W0823 09:22:09.996123 140449374000960 deprecation.py:323] From /home/haonly/anaconda3/envs/hayeon/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0823 09:22:10.068253 140449374000960 deprecation.py:506] From /home/haonly/anaconda3/envs/hayeon/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0823 09:22:10.545424 140449374000960 deprecation.py:323] From /home/haonly/anaconda3/envs/hayeon/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0823 09:22:10.731195 140449374000960 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/base_model.py:23: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "I0823 09:22:11.580108 140449374000960 base_model.py:27] Initializing tf session\n",
      "W0823 09:22:11.581272 140449374000960 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/base_model.py:28: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0823 09:22:11.623694 140449374000960 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/base_model.py:29: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0823 09:22:12.309781 140449374000960 deprecation_wrapper.py:119] From /home/haonly/ner with tensor_v5/model/base_model.py:30: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:22:12.357988 140449374000960 base_model.py:33] Reloading the latest trained model...\n",
      "W0823 09:22:12.359168 140449374000960 deprecation.py:323] From /home/haonly/anaconda3/envs/hayeon/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "model.restore_session(config.dir_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=CoNLLDataset(config.filename_test,config.processing_word,config.processing_tag,config.max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:22:12.525486 140449374000960 base_model.py:70] Testing model over test set\n",
      "I0823 09:22:18.066494 140449374000960 base_model.py:74] acc 97.87 - f1 88.80\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:22:18.075587 140449374000960 <ipython-input-3-9071d355460a>:12] \n",
      "This is an interactive mode.\n",
      "To exit, enter 'exit'.\n",
      "You can enter a sentence like\n",
      "input> I love Paris\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  Samsung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:26:50.460769 140449374000960 <ipython-input-3-9071d355460a>:31] Samsung \n",
      "I0823 09:26:50.462218 140449374000960 <ipython-input-3-9071d355460a>:31] B-ORG   \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  Tesla CEO, Elon Musk is from South Africa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:28:41.611024 140449374000960 <ipython-input-3-9071d355460a>:31] Tesla CEO, Elon  Musk is from South Africa. \n",
      "I0823 09:28:41.612422 140449374000960 <ipython-input-3-9071d355460a>:31] O     O    I-ORG O    O  O    B-LOC I-LOC   \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  Elon Musk is a CEO of Tesla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:29:57.795937 140449374000960 <ipython-input-3-9071d355460a>:31] Elon  Musk  is a CEO   of    Tesla \n",
      "I0823 09:29:57.797388 140449374000960 <ipython-input-3-9071d355460a>:31] B-ORG I-ORG O  O B-ORG I-ORG I-ORG \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  There are three CEO in Samsung.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:30:41.455348 140449374000960 <ipython-input-3-9071d355460a>:31] There are three CEO   in Samsung. \n",
      "I0823 09:30:41.456768 140449374000960 <ipython-input-3-9071d355460a>:31] O     O   O     B-ORG O  B-LOC    \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  Britain first began talks to join the EEC in July 1961.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:31:59.131392 140449374000960 <ipython-input-3-9071d355460a>:31] Britain first began talks to join the EEC   in July 1961. \n",
      "I0823 09:31:59.132839 140449374000960 <ipython-input-3-9071d355460a>:31] B-LOC   O     O     O     O  O    O   B-ORG O  O    O     \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  Samsung was founded as a grocery trading store on March 1, 1938, by Lee Byung-Chull.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:33:25.779127 140449374000960 <ipython-input-3-9071d355460a>:31] Samsung was founded as a grocery trading store on March 1, 1938, by Lee   Byung-Chull. \n",
      "I0823 09:33:25.780550 140449374000960 <ipython-input-3-9071d355460a>:31] B-ORG   O   O       O  O O       O       O     O  O     O  O     O  B-PER I-PER        \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  Samsung was founded on March 1, 1938, by Lee Byung-Chull.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:33:46.493216 140449374000960 <ipython-input-3-9071d355460a>:31] Samsung was founded on March 1, 1938, by Lee   Byung-Chull. \n",
      "I0823 09:33:46.494527 140449374000960 <ipython-input-3-9071d355460a>:31] B-ORG   O   O       O  O     O  O     O  B-PER I-PER        \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  Lauren is from Saudi Arabia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:34:20.872584 140449374000960 <ipython-input-3-9071d355460a>:31] Lauren is from Saudi Arabia \n",
      "I0823 09:34:20.874008 140449374000960 <ipython-input-3-9071d355460a>:31] B-PER  O  O    B-LOC I-LOC  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  Hayeon and Cheol Su are friends.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:35:08.123112 140449374000960 <ipython-input-3-9071d355460a>:31] Hayeon and Cheol Su    are friends. \n",
      "I0823 09:35:08.124749 140449374000960 <ipython-input-3-9071d355460a>:31] B-ORG  O   B-ORG I-ORG O   O        \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  Hayeon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:35:13.758690 140449374000960 <ipython-input-3-9071d355460a>:31] Hayeon \n",
      "I0823 09:35:13.759944 140449374000960 <ipython-input-3-9071d355460a>:31] B-ORG  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  Tim Cook is leading Apple company.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:36:00.892582 140449374000960 <ipython-input-3-9071d355460a>:31] Tim   Cook  is leading Apple company. \n",
      "I0823 09:36:00.893988 140449374000960 <ipython-input-3-9071d355460a>:31] B-PER I-PER O  O       B-ORG O        \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  How long has Spain colonized South America?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:44:08.994053 140449374000960 <ipython-input-3-9071d355460a>:31] How long has Spain colonized South America? \n",
      "I0823 09:44:08.995728 140449374000960 <ipython-input-3-9071d355460a>:31] O   O    O   B-LOC O         B-LOC I-MISC   \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  How long has Spain colonized South America ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:44:21.328487 140449374000960 <ipython-input-3-9071d355460a>:31] How long has Spain colonized South America ? \n",
      "I0823 09:44:21.329673 140449374000960 <ipython-input-3-9071d355460a>:31] O   O    O   B-LOC O         B-LOC I-LOC   O \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input>  UN has announced something.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 09:46:27.964511 140449374000960 <ipython-input-3-9071d355460a>:31] UN    has announced something. \n",
      "I0823 09:46:27.965559 140449374000960 <ipython-input-3-9071d355460a>:31] B-ORG O   O         O          \n"
     ]
    }
   ],
   "source": [
    "interactive_shell(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=[[[[0,1,2,3],[4,5,6,7]],[[8,9,10,11],[12,13,14,15]],[[16,17,18,19],[20,21,22,23]],[[24,25,26,27],[28,29,30,31]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.reduce_max(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as se:\n",
    "    print(se.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hayeon",
   "language": "python",
   "name": "hayeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
